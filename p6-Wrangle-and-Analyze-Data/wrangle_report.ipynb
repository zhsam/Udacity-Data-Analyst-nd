{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle Report - Data Wrangling for Twitter - WeRateDog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This report documents my wrangling efforts in Udacity DAND Term2 - Twitter WeRateDog project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Wrangling process consists of three steps: gathering data, aseesing data, cleaning data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step1- Gathering Data\n",
    "\n",
    "There are 3 sources of gathering data for this project:<br>\n",
    "\n",
    "(1) WeRateDog' Twitter Archive:\n",
    "I manually download WeRateDogs' Twitter archive data from Udacity and read it through `Pandas`.\n",
    "\n",
    "(2) Tweet Image Predictions:\n",
    "- First use `requests` function to get the data from the url. \n",
    "- Then I use the file system in Python to read the data I gathered using `requests` and store it in the folder\n",
    "- Third, I read the `.tsv` using `Pandas`.\n",
    "\n",
    "(3) WeRateDog data from API:\n",
    "This part is bit more tricky,\n",
    "- First, I created a `.txt` and store an empty json data in the file.\n",
    "- Second, I created a `for` loop that run through all the tweet_id in `Twitter Archive` data. For each tweet_id, I use `Tweepy` to get the status data and store all the values I'm interested. \n",
    "- The third step is to use the `read_json` function to read the json file from the `.txt` we gathered using `Tweepy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2- Assessing Data\n",
    "\n",
    "This part can separated into two small parts- visual assessment and programmatic assessment.\n",
    "\n",
    "- Visual Assessment <br>\n",
    "In this part, I visually looked at each dataframe, try to see if there's anything unusual.\n",
    "<br><br>\n",
    "- Programmatic Assessment <br>\n",
    "In this part, I leverage `Pandas`'s great functions sush as `.sample()`, `.info()`, `.value_counts()`, `.describe()` try to see if there's any data quality/tidiness issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step3- Cleaning Data\n",
    "\n",
    "Each Data Cleaning process can be separated into three parts - `define`, `code`, `test`.\n",
    "\n",
    "First of all, I look at all the issues I found during the Assessment process. The following are all the issues I found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### >> Quality Issues\n",
    "\n",
    "##### wrd archive\n",
    "- (1) There are 55 status having incorrect name: \"a\", \"an\".\n",
    "- (2) Some entries has the wrong expanded_urls - \"gofundme.com\" instead of \"twitter.com\".\n",
    "- (3) There are 59 status missing \"expanded_urls\".\n",
    "- (4) Change all the null values to be NaN in 'name', 'doggo', 'floofer', 'pupper', 'puppo' columns.\n",
    "- (5) The rating_numerator contains ratings that should sometimes be in decimals, but are incorrectly parsed. This value should be a float.\n",
    "- (6) Some ratings are incorrectly retrieved from other fractions, e.g. row 2335 - 1/2\n",
    "- (7) IDs columns should be strings instead of integers.\n",
    "\n",
    "##### prediction\n",
    "- (9) Some of the prediction results starts with capital letters. e.g. Labrador_retriever\n",
    "\n",
    "#### >> Tidiness Issues\n",
    "\n",
    "##### wrd archive\n",
    "- (10) doggo, floofer, pupper, puppo should be in the same column - type <br>\n",
    "\n",
    "##### wrd_api\n",
    "- (11) Convert columns into rows \n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrangling Efforts in Quality Issues:\n",
    "\n",
    "#### - Issues (1):\n",
    "- I used `df.query()` function tried to understand what are the texts in the original posts. \n",
    "- Then, I realized that these are the pets that doesn't specified their names in the posts. \n",
    "- As a results, I used `df.apply()` and change all the incorrect name into 'NaN'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Issues (2) and (3)\n",
    "- I used `df.apply()` function to fix incorrect status urls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Issues (4)\n",
    "- I used `df.apply()` and change all the 'None' values into 'NaN' in 'doggo', 'floofer', 'pupper', 'puppo' columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Issues (5) and (6)\n",
    "- I used `.str.extract()` along with regular expression to extract correct ratings from `text` column\n",
    "- Then I used `df.apply()` to get the ratings data for `rating_numerator` and `rating_denominator`.\n",
    "- I used `.astype()` function to convert `rating_numerator` to correct data type.\n",
    "- This is the regular expression I used: `r'(\\d+\\.?\\d+?/\\d+\\.?\\d+?)'` which captured decimals with in all the ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Issues (7)\n",
    "- I used `.astype()` function to convert `tweet_id`, `in_reply_to_status_id`, `in_reply_to_user_id`, `retweeted_status_id` and `retweeted_status_user_id` columns in wrd_clean dataframe and `tweet_id` column in prediction_clean dataframe into correct data type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Issues (8)\n",
    "- I used `df.apply()` function and `.lower()` function in order to change all the letters into lower case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrangling Efforts in Tidiness Issues:\n",
    "\n",
    "#### - Issues (1):\n",
    "- I created many temporary columns to store the dog types data using `df.apply()` function.\n",
    "- I joined all the temporary dataframes I created.\n",
    "- Drop all the temporary dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Issues (2):\n",
    "- First, I used `df.copy()` function before doing anything.\n",
    "- I use `.transpose()` funcion to transpose the whole dataframe.\n",
    "- I use the `.rename()` function to rename columns to proper name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above are all the efforts I had during the data wrangling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
